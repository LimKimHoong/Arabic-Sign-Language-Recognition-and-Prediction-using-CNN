# Arabic-Sign-Language-Recognition-and-Prediction-using-CNN

Abstract : 

Arabic Sign Language (ArSL) is a vital form of communication used by the deaf and hard-of-hearing community in Arabic-speaking countries. Recognizing and understanding ArSL gestures play a crucial role in facilitating effective communication between hearing-impaired individuals and the broader society. This research paper focuses on the development of a robust ArSL Recognition and Prediction system using Convolutional Neural Networks (CNNs). To train the CNN model, an extensive dataset of ArSL gestures containing 50,000 images is collected, annotated, and preprocessed. The CNN architecture is designed and optimized for ArSL recognition, incorporating multiple convolutional layers, pooling layers, and fully connected layers. The model is trained using a large-scale dataset and employs appropriate regularization techniques to mitigate overfitting. The trained model achieves high accuracy of 97.12%, in recognizing individual signs and can predict subsequent signs in a continuous sequence, thereby enabling real-time interpretation. Extensive experiments and evaluations are conducted to assess the performance of the proposed system. The results demonstrate that the CNN-based approach outperforms traditional machine learning techniques and achieves state- of-the-art accuracy in ArSL recognition and prediction. The research findings contribute to the advancement of ArSL recognition technology, enabling improved accessibility and inclusivity for the deaf and hard-of-hearing community in Arabic-speaking regions. The developed CNN model provides a foundation for the development of assistive technologies, such as sign language translation systems and augmented reality applications, that can bridge the communication gap between hearing-impaired individuals and the larger society.

Keywords: CNN, ArSL Recognition, Image Classification
